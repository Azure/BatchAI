{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer GPU Distributed-Infiniband\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This example demonstrates how to run standard ChainerMN [train_mnist.py](https://github.com/chainer/chainermn/blob/master/examples/mnist/train_mnist.py) distributed training job using Batch AI with Infiniband enabled.\n",
    "\n",
    "## Details\n",
    "\n",
    "- Standard chainer sample script [train_mnist.py](https://github.com/chainer/chainermn/blob/master/examples/mnist/train_mnist.py) is used;\n",
    "- Chainer downloads the standard MNIST Database on its own and distributed across workers;\n",
    "- Standard output of the job and the model will be stored on Azure File Share.\n",
    "- IntelMPI (non-CUDA-aware) will be used to launch ChainerMN jobs cross nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "### Install Dependencies and Create Configuration file.\n",
    "Follow [instructions](/recipes) to install all dependencies and create configuration file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Configuration and Create Batch AI client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbpresent": {
     "id": "bfa11f00-8866-4051-bbfe-a9646e004910"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: (1783, 'CredWrite', 'The stub received bad data')\n",
      "Keyring cache token has failed: (1783, 'CredWrite', 'The stub received bad data')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from azure.storage.file import FileService\n",
    "import azure.mgmt.batchai.models as models\n",
    "\n",
    "# The BatchAI/utilities folder contains helper functions used by different notebooks\n",
    "sys.path.append('../../../')\n",
    "import utilities as utils\n",
    "\n",
    "cfg = utils.config.Configuration('../../configuration.json')\n",
    "client = utils.config.create_batchai_client(cfg)\n",
    "utils.config.create_resource_group(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Resoruce Group and Batch AI workspace if not exists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyring cache token has failed: (1783, 'CredWrite', 'The stub received bad data')\n"
     ]
    }
   ],
   "source": [
    "utils.config.create_resource_group(cfg)\n",
    "_ = client.workspaces.create(cfg.resource_group, cfg.workspace, cfg.location).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Azure Batch AI Compute Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Compute Cluster\n",
    "\n",
    "- For this example we will use a gpu cluster of `STANDARD_NC24r` nodes, which equip with infiniband device. Number of nodes in the cluster is configured with `nodes_count` variable, and 2 nodes will be used by default.\n",
    "- Please be sure you have enough core quota to create at lesat two `STANDARD_NC24r` nodes.\n",
    "- We will call the cluster `nc24r`\n",
    "- If you like to conduct performance comparasion with TCP network, you can create the cluster with VM size `STANDARD_NC24` that does not support Infiniband \n",
    "\n",
    "So, the cluster will have the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_count = 2\n",
    "cluster_name = 'nc24r'\n",
    "\n",
    "parameters = models.ClusterCreateParameters(\n",
    "    vm_size='STANDARD_NC24r',\n",
    "    scale_settings=models.ScaleSettings(\n",
    "        manual=models.ManualScaleSettings(target_node_count=nodes_count)\n",
    "    ),\n",
    "    user_account_settings=models.UserAccountSettings(\n",
    "        admin_user_name=cfg.admin,\n",
    "        admin_user_password=cfg.admin_password or None,\n",
    "        admin_user_ssh_public_key=cfg.admin_ssh_key or None\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Compute Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = client.clusters.create(cfg.resource_group, cfg.workspace, cluster_name, parameters).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Cluster Creation\n",
    "\n",
    "Monitor the just created cluster. The `utilities` module contains a helper function to print out detail status of the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: steady Target: 2; Allocated: 2; Idle: 2; Unusable: 0; Running: 0; Preparing: 0; Leaving: 0\n"
     ]
    }
   ],
   "source": [
    "cluster = client.clusters.get(cfg.resource_group, cfg.workspace, cluster_name)\n",
    "utils.cluster.print_cluster_status(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare Training Script in Azure Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create File Share\n",
    "\n",
    "For this example we will create a new File Share with name `batchaisample` under your storage account.\n",
    "\n",
    "**Note** You don't need to create new file share for every cluster. We are doing this in this sample to simplify resource management for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "azure_file_share_name = 'batchaisample'\n",
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.create_share(azure_file_share_name, fail_on_exist=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Sample Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download original sample script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/chainer/chainermn/v1.3.0/examples/mnist/train_mnist.py ...Done\n"
     ]
    }
   ],
   "source": [
    "script_to_deploy = 'train_mnist.py'\n",
    "utils.dataset.download_file('https://raw.githubusercontent.com/chainer/chainermn/v1.3.0/examples/mnist/train_mnist.py', script_to_deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a folder on Azure File Share containing a copy of the sample script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_dir = 'chainer_samples'\n",
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.create_directory(\n",
    "    azure_file_share_name, samples_dir, fail_on_exist=False)\n",
    "service.create_file_from_path(\n",
    "    azure_file_share_name, samples_dir, script_to_deploy, script_to_deploy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the job preparation script [jobprep.sh](./jobprep.sh), that installs IntelMPI binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.create_file_from_path(\n",
    "    azure_file_share_name, samples_dir, 'jobprep.sh', 'jobprep.sh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Job\n",
    "- The job will use `batchaitraining/chainermn:IntelMPI` container. The dockerfile can be found [here](./dockerfile);\n",
    "- We will mount file share at folder with name `afs`. Full path of this folder on a computer node will be `$AZ_BATCHAI_JOB_MOUNT_ROOT/afs`;\n",
    "- Will run modified `train_mnist.py` from SCRIPT input directory;\n",
    "- Will output standard output and error streams to file share;\n",
    "- IntelMPI binary will be installed via Job Preparation task;\n",
    "- Will generate output model files in MODEL output directory. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_file_share = 'afs'\n",
    "parameters = models.JobCreateParameters(\n",
    "     cluster=models.ResourceId(id=cluster.id),\n",
    "     node_count=2,\n",
    "     mount_volumes=models.MountVolumes(\n",
    "        azure_file_shares=[\n",
    "            models.AzureFileShareReference(\n",
    "                account_name=cfg.storage_account_name,\n",
    "                credentials=models.AzureStorageCredentialsInfo(\n",
    "                    account_key=cfg.storage_account_key),\n",
    "                azure_file_url='https://{0}.file.core.windows.net/{1}'.format(\n",
    "                    cfg.storage_account_name, azure_file_share_name),\n",
    "                relative_mount_path=azure_file_share)\n",
    "        ]\n",
    "     ),  \n",
    "     std_out_err_path_prefix='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}'.format(azure_file_share),\n",
    "     output_directories = [\n",
    "        models.OutputDirectory(\n",
    "            id='MODEL',\n",
    "            path_prefix='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}'.format(azure_file_share),\n",
    "            path_suffix='Models')],\n",
    "     job_preparation=models.JobPreparation(\n",
    "         command_line='bash $AZ_BATCHAI_JOB_MOUNT_ROOT/{0}/{1}/jobprep.sh'.format(azure_file_share, samples_dir)),\n",
    "     container_settings=models.ContainerSettings(\n",
    "         image_source_registry=models.ImageSourceRegistry(image='batchaitraining/chainermn:IntelMPI')),\n",
    "     chainer_settings = models.ChainerSettings(\n",
    "         python_script_file_path='$AZ_BATCHAI_JOB_MOUNT_ROOT/{0}/{1}/{2}'.format(azure_file_share, samples_dir, script_to_deploy),\n",
    "         command_line_args='-g --communicator non_cuda_aware -o $AZ_BATCHAI_OUTPUT_MODEL',\n",
    "         process_count=8\n",
    "     ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a training Job and wait for Job completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Job chainer_07_25_2018_071026 in Experiment chainermn_experiment\n"
     ]
    }
   ],
   "source": [
    "experiment_name = 'chainermn_experiment'\n",
    "experiment = client.experiments.create(cfg.resource_group, cfg.workspace, experiment_name).result()\n",
    "job_name = datetime.utcnow().strftime('chainer_%m_%d_%Y_%H%M%S')\n",
    "job = client.jobs.create(cfg.resource_group, cfg.workspace, experiment_name, job_name, parameters).result()\n",
    "print('Created Job {0} in Experiment {1}'.format(job.name, experiment.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait for Job to Finish\n",
    "The job will start running when the cluster will have enough idle nodes. The following code waits for job to start running printing the cluster state. During job run, the code prints current content of stdout.txt.\n",
    "\n",
    "**Note** Execution may take several minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster state: steady Target: 2; Allocated: 2; Idle: 0; Unusable: 0; Running: 2; Preparing: 0; Leaving: 0\n",
      "Job state: running ExitCode: None\n",
      "Waiting for job output to become available...\n",
      "==========================================\n",
      "Num process (COMM_WORLD): 8\n",
      "Using GPUs\n",
      "Using non_cuda_aware communicator\n",
      "Num unit: 1000\n",
      "Num Minibatch-size: 100\n",
      "Num epoch: 20\n",
      "==========================================\n",
      "epoch       main/loss   validation/main/loss  main/accuracy  validation/main/accuracy  elapsed_time\n",
      "\u001b[J1           0.394735    0.153702              0.880933       0.954712                  9.935         \n",
      "\u001b[J     total [###...............................................]  6.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       100 iter, 1 epoch / 20 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J2           0.12691     0.102421              0.963467       0.967019                  11.5765       \n",
      "\u001b[J     total [######............................................] 13.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       200 iter, 2 epoch / 20 epochs\n",
      "    48.382 iters/sec. Estimated time to finish: 0:00:26.869530.\n",
      "\u001b[4A\u001b[J3           0.0739991   0.0756993             0.978534       0.975769                  13.1478       \n",
      "\u001b[J4           0.0482113   0.0673389             0.985867       0.978077                  14.8074       \n",
      "\u001b[J     total [##########........................................] 20.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       300 iter, 4 epoch / 20 epochs\n",
      "    45.067 iters/sec. Estimated time to finish: 0:00:26.627189.\n",
      "\u001b[4A\u001b[J5           0.0331028   0.060193              0.990133       0.980192                  16.3799       \n",
      "\u001b[J     total [#############.....................................] 26.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       400 iter, 5 epoch / 20 epochs\n",
      "    46.693 iters/sec. Estimated time to finish: 0:00:23.558060.\n",
      "\u001b[4A\u001b[J6           0.0228456   0.0555588             0.993867       0.98125                   17.927        \n",
      "\u001b[J     total [################..................................] 33.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       500 iter, 6 epoch / 20 epochs\n",
      "    47.579 iters/sec. Estimated time to finish: 0:00:21.017763.\n",
      "\u001b[4A\u001b[J7           0.0167275   0.0612587             0.9956         0.981442                  19.4854       \n",
      "\u001b[J8           0.0114123   0.0632592             0.998          0.981346                  21.193        \n",
      "\u001b[J     total [####################..............................] 40.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       600 iter, 8 epoch / 20 epochs\n",
      "    45.839 iters/sec. Estimated time to finish: 0:00:19.633780.\n",
      "\u001b[4A\u001b[J9           0.00785209  0.0588524             0.997867       0.983173                  22.8255       \n",
      "\u001b[J     total [#######################...........................] 46.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "       700 iter, 9 epoch / 20 epochs\n",
      "    46.538 iters/sec. Estimated time to finish: 0:00:17.190099.\n",
      "\u001b[4A\u001b[J10          0.00650034  0.0664207             0.998          0.979904                  24.3993       \n",
      "\u001b[J     total [##########################........................] 53.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "       800 iter, 10 epoch / 20 epochs\n",
      "    47.027 iters/sec. Estimated time to finish: 0:00:14.885195.\n",
      "\u001b[4A\u001b[J11          0.00429369  0.0633699             0.999067       0.98375                   25.9573       \n",
      "\u001b[J12          0.00192037  0.0627383             0.999867       0.983654                  27.5356       \n",
      "\u001b[J     total [##############################....................] 60.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "       900 iter, 12 epoch / 20 epochs\n",
      "    46.619 iters/sec. Estimated time to finish: 0:00:12.870411.\n",
      "\u001b[4A\u001b[J13          0.00127659  0.0610483             0.999733       0.983846                  29.0739       \n",
      "\u001b[J     total [#################################.................] 66.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      1000 iter, 13 epoch / 20 epochs\n",
      "    46.972 iters/sec. Estimated time to finish: 0:00:10.644648.\n",
      "\u001b[4A\u001b[J14          0.000616517  0.0620528             1              0.984231                  30.6628       \n",
      "\u001b[J     total [####################################..............] 73.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1100 iter, 14 epoch / 20 epochs\n",
      "    47.305 iters/sec. Estimated time to finish: 0:00:08.455838.\n",
      "\u001b[4A\u001b[J15          0.000504799  0.0626153             1              0.983846                  32.2127       \n",
      "\u001b[J16          0.000361354  0.0631169             1              0.984519                  33.8322       \n",
      "\u001b[J     total [########################################..........] 80.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      1200 iter, 16 epoch / 20 epochs\n",
      "    46.851 iters/sec. Estimated time to finish: 0:00:06.403234.\n",
      "\u001b[4A\u001b[J17          0.000324203  0.0637248             1              0.984327                  35.4309       \n",
      "\u001b[J     total [###########################################.......] 86.67%\n",
      "this epoch [################..................................] 33.33%\n",
      "      1300 iter, 17 epoch / 20 epochs\n",
      "    46.959 iters/sec. Estimated time to finish: 0:00:04.259010.\n",
      "\u001b[4A\u001b[J18          0.000279929  0.0647316             1              0.984135                  37.0443       \n",
      "\u001b[J     total [##############################################....] 93.33%\n",
      "this epoch [#################################.................] 66.67%\n",
      "      1400 iter, 18 epoch / 20 epochs\n",
      "    47.234 iters/sec. Estimated time to finish: 0:00:02.117141.\n",
      "\u001b[4A\u001b[J19          0.000246038  0.0654415             1              0.984327                  38.5943       \n",
      "\u001b[J20          0.000219682  0.0656924             1              0.984327                  40.178        \n",
      "\u001b[J     total [##################################################] 100.00%\n",
      "this epoch [..................................................]  0.00%\n",
      "      1500 iter, 20 epoch / 20 epochs\n",
      "    46.949 iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[JJob state: succeeded ExitCode: 0\n"
     ]
    }
   ],
   "source": [
    "utils.job.wait_for_job_completion(client, cfg.resource_group, cfg.workspace, \n",
    "                                  experiment_name, job_name, cluster_name, 'stdouterr', 'stdout.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### List stdout.txt and stderr.txt files for the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution-tvm-913932285_1-20180725t045847z.log https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/execution-tvm-913932285_1-20180725t045847z.log?sv=2016-05-31&sr=f&sig=XXaVGOLgBTr%2FApV7j2tmBq3qpUKhw86T%2F%2BR6aDKXTUg%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "execution-tvm-913932285_2-20180725t045847z.log https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/execution-tvm-913932285_2-20180725t045847z.log?sv=2016-05-31&sr=f&sig=XxIrNPcBDk3vJfwNw%2BOGu%2FT0sTHIm4oi6wrlb6jRHwE%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stderr-job_prep-tvm-913932285_1-20180725t045847z.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stderr-job_prep-tvm-913932285_1-20180725t045847z.txt?sv=2016-05-31&sr=f&sig=EY1r9IKcfL4Q241LQRCGRqd3jDoE7Zq4pwR27yTFVFY%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stderr-job_prep-tvm-913932285_2-20180725t045847z.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stderr-job_prep-tvm-913932285_2-20180725t045847z.txt?sv=2016-05-31&sr=f&sig=yldyoRltyTiyWugSZkRlziwlmpRoQfru72%2FkeKGPOGo%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stderr.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stderr.txt?sv=2016-05-31&sr=f&sig=qAUQaZD1wrBKOQl3zGBjAyNVCxDkcAu9PMMcQNXpgPs%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stdout-job_prep-tvm-913932285_1-20180725t045847z.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stdout-job_prep-tvm-913932285_1-20180725t045847z.txt?sv=2016-05-31&sr=f&sig=tnNWqflh1NCzHa4znxFqOOeZsGDhLhkklUZ0fcQ2yP8%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stdout-job_prep-tvm-913932285_2-20180725t045847z.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stdout-job_prep-tvm-913932285_2-20180725t045847z.txt?sv=2016-05-31&sr=f&sig=TXJU6%2B6svC0a1Axj1bCZ3cENt%2FGhiDgn7skWWPN%2BVfI%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n",
      "stdout.txt https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_052122/358c8acf-1348-43ea-97c2-eb3389885a48/stdouterr/stdout.txt?sv=2016-05-31&sr=f&sig=ItqaGNsLslF83L%2FZmpR6jqQvdRbD5ntW%2F6MoTH8l5%2Fo%3D&se=2018-07-25T06%3A28%3A46Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "files = client.jobs.list_output_files(cfg.resource_group, cfg.workspace, experiment_name, job_name,\n",
    "                                      models.JobsListOutputFilesOptions(outputdirectoryid='stdouterr')) \n",
    "for f in list(files):\n",
    "    print(f.name, f.download_url or 'directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enumerate Model Output\n",
    "Previously we configured the job to use output directory with `ID='MODEL'` for model output. We can enumerate the output using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token expired or is invalid. Attempting to refresh.\n",
      "Keyring cache token has failed: (1783, 'CredWrite', 'The stub received bad data')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cg.dot https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_071026/888531e9-f8af-47e0-8fe6-fa1714147bc9/outputs/Models/cg.dot?sv=2016-05-31&sr=f&sig=INP00Jl%2Bef%2FnBSeMhL0a7vcjITh4qa7t8%2FtKhFenkAU%3D&se=2018-07-25T21%3A02%3A12Z&sp=rl\n",
      "log https://stgacc07062018192335.file.core.windows.net/batchaisample/1cba1da6-5a83-45e1-a88e-8b397eb84356/batchaitestrgnortheuro/workspaces/pgunda/experiments/chainermn_experiment/jobs/chainer_07_25_2018_071026/888531e9-f8af-47e0-8fe6-fa1714147bc9/outputs/Models/log?sv=2016-05-31&sr=f&sig=3A3%2FY3ozgorKV62SeUQvIj0ChpblE%2Fcn4GNWoC9xMAk%3D&se=2018-07-25T21%3A02%3A12Z&sp=rl\n"
     ]
    }
   ],
   "source": [
    "files = client.jobs.list_output_files(cfg.resource_group, cfg.workspace, experiment_name, job_name,\n",
    "                                      models.JobsListOutputFilesOptions(outputdirectoryid='MODEL')) \n",
    "for f in list(files):\n",
    "    print(f.name, f.download_url or 'directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = client.jobs.delete(cfg.resource_group, cfg.workspace, experiment_name, job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the Cluster\n",
    "When you are finished with the sample and don't want to submit any more jobs you can delete the cluster using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_ = client.clusters.delete(cfg.resource_group, cfg.workspace, cluster_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Delete File Share\n",
    "When you are finished with the sample and don't want to submit any more jobs you can delete the file share completely with all files using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = FileService(cfg.storage_account_name, cfg.storage_account_key)\n",
    "service.delete_share(azure_file_share_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
